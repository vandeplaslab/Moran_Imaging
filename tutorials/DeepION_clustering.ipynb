{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb0beffd-d06c-48b8-bf4c-cecadbdb73d2",
   "metadata": {},
   "source": [
    "### Colocalization-based ion image clusternig with DeepION\n",
    "\n",
    "Publication: \"DeepION: A Deep Learning-Based Low-Dimensional Representation Model of Ion Images for Mass Spectrometry Imaging\" by Lei Guo. Analytical Chemistry. 2024. https://pubs.acs.org/doi/full/10.1021/acs.analchem.3c05002\n",
    "\n",
    "Code by Lei Guo: https://github.com/gankLei-X/DeepION/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38445b1-f1d4-4395-870d-37fd416f78eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\anaconda3\\envs\\spatial_IMS_env_compare\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import HDBSCAN\n",
    "import random\n",
    "import umap\n",
    "\n",
    "# Import necessary Moran Imaging modules\n",
    "from moran_imaging.ari_balance import balanced_adjusted_rand_index\n",
    "from moran_imaging.vmeasure_balance import balanced_homogeneity_completeness_v_measure\n",
    "\n",
    "# Import necessary DeepION module\n",
    "from moran_imaging.deep_ion_clustering import DeepION_training, DeepION_predicting\n",
    "\n",
    "# Fix random seed\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "008d2b73-f73e-4d27-b7b6-8916e3f1eed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "Quadro RTX 5000\n",
      "Torch CUDA Version: 12.4\n",
      "Torch Backend CUDA Available: True\n"
     ]
    }
   ],
   "source": [
    "# Verify GPU availability\n",
    "print(torch.cuda.is_available())  \n",
    "print(torch.cuda.device_count())  \n",
    "print(torch.cuda.get_device_name(0))  \n",
    "print(\"Torch CUDA Version:\", torch.version.cuda)\n",
    "print(\"Torch Backend CUDA Available:\", torch.backends.cudnn.enabled)\n",
    "\n",
    "# Set CUDA device \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ac43c-a834-4924-a4c8-3ab0b7a9bba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f08ddee1-0997-4cbd-8fbe-4e2a16d13b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ion_image(data, image_shape, background_mask, fill_zeros=True, show_image=True, colormap='coolwarm'):\n",
    "    \n",
    "    # Fill background pixels with zeros (default) or NaN\n",
    "    pixel_grid = np.zeros((image_shape[0]*image_shape[1], ))\n",
    "    pixel_grid[np.invert(background_mask)] = data\n",
    "    \n",
    "    if not fill_zeros:\n",
    "        pixel_grid[background_mask] = np.nan\n",
    "    \n",
    "    # Reshape data\n",
    "    ion_image = np.reshape(pixel_grid, image_shape)\n",
    "    \n",
    "    # Plot ion image \n",
    "    if show_image == True: \n",
    "        plt.figure(dpi=100)\n",
    "        plt.imshow(ion_image, cmap=colormap)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    return ion_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a688eedf-b816-445a-8ade-1b9c039e3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train DeepION model\n",
    "def train_deepion(input_matrix, input_shape, mode=\"COL\"):\n",
    "    \"\"\"\n",
    "    Runs DeepION training with the given MSI dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        input_matrix (str): Path to the MSI data matrix file.\n",
    "        input_shape (tuple): Shape of the MSI dataset (height, width).\n",
    "        mode (str): Mode of operation, either 'COL' (colocalization) or 'ISO' (isotope discovery).\n",
    "    \"\"\"\n",
    "    print(\"Starting DeepION training...\")\n",
    "    DeepION_training(input_matrix, input_shape, mode)\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "# Function to run DeepION feature extraction\n",
    "def predict_deepion(input_matrix, input_shape, mode=\"COL\"):\n",
    "    \"\"\"\n",
    "    Runs DeepION feature extraction on the given MSI dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        input_matrix (str): Path to the MSI data matrix file.\n",
    "        input_shape (tuple): Shape of the MSI dataset (height, width).\n",
    "        mode (str): Mode of operation, either 'COL' (colocalization) or 'ISO' (isotope discovery).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Extracted feature matrix.\n",
    "    \"\"\"\n",
    "    print(\"Extracting features using DeepION...\")\n",
    "    features = DeepION_predicting(input_matrix, input_shape, mode)\n",
    "    print(\"Feature extraction completed!\")\n",
    "    return features\n",
    "\n",
    "# Function to apply dimensionality reduction\n",
    "def reduce_dimensionality(features):\n",
    "    \"\"\"\n",
    "    Applies dimensionality reduction to extracted features.\n",
    "    \n",
    "    Parameters:\n",
    "        features (np.ndarray): Feature matrix extracted from DeepION.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Low-dimensional feature representation.\n",
    "    \"\"\"\n",
    "    print(\"Applying dimensionality reduction...\")\n",
    "\n",
    "    features_umap = umap.UMAP(n_components=20, metric='cosine', random_state=0).fit_transform(features)\n",
    "    features_umap = MinMaxScaler().fit_transform(features_umap)\n",
    "    \n",
    "    print(\"Dimensionality reduction completed!\")\n",
    "    return features_umap\n",
    "\n",
    "# Function to run co-localized ion searching\n",
    "def run_colocalized_search(ld_features, peak_list, num=5, output_file=\"output/\"):\n",
    "    \"\"\"\n",
    "    Runs co-localized ion searching using DeepION features.\n",
    "    \n",
    "    Parameters:\n",
    "        ld_features (np.ndarray): Low-dimensional feature representation.\n",
    "        peak_list (str): Path to MSI peak list file.\n",
    "        num (int): Number of co-localized ions to search for each ion.\n",
    "        output_file (str): Path to save results.\n",
    "    \"\"\"\n",
    "    print(f\"Running co-localized ion searching (Top {num} ions)...\")\n",
    "    Co_localizedIONSearching(ld_features, peak_list, num, output_file)\n",
    "    print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf5f1ef-eb63-418c-b624-6aeb48b36ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e81f37-66f3-4004-84d9-b2b49aa55ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a9fe2bc-c1d3-4e13-886a-b6aef03e8307",
   "metadata": {},
   "source": [
    "#### Transform zebra-fish dataset into a DeepION-compatible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ab545f-7716-4c02-aea2-883b8ed23695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "with open('Zebra_fish_8_clusters_dataset.pickle', 'rb') as file:\n",
    "    clustering_data_metadata = pickle.load(file) \n",
    "\n",
    "image_shape = clustering_data_metadata['utils']['image_shape']\n",
    "background_mask = clustering_data_metadata['utils']['background_mask']\n",
    "data_cluster1 = clustering_data_metadata['cluster_1']['data'] \n",
    "data_cluster2 = clustering_data_metadata['cluster_2']['data']\n",
    "data_cluster3 = clustering_data_metadata['cluster_3']['data']\n",
    "data_cluster4 = clustering_data_metadata['cluster_4']['data']\n",
    "data_cluster5 = clustering_data_metadata['cluster_5']['data']\n",
    "data_cluster6 = clustering_data_metadata['cluster_6']['data']\n",
    "data_cluster7 = clustering_data_metadata['cluster_7']['data']\n",
    "data_cluster8 = clustering_data_metadata['cluster_8']['data']\n",
    "\n",
    "# Reference cluster labels\n",
    "ref_labels = ([1]*data_cluster1.shape[1] + [2]*data_cluster2.shape[1] + [3]*data_cluster3.shape[1] + [4]*data_cluster4.shape[1] + [5]*data_cluster5.shape[1] +\n",
    "              [6]*data_cluster6.shape[1] + [7]*data_cluster7.shape[1] + [8]*data_cluster8.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb4390-62a2-44fb-858a-f49b1886d4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6439e3c0-b428-4b6d-a64b-a9af3267e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add off-tissue pixels to each ion image\n",
    "dataset = np.hstack((data_cluster1, data_cluster2, data_cluster3, data_cluster4, data_cluster5, data_cluster6, data_cluster7, data_cluster8))\n",
    "total_num_pixels = np.prod(image_shape)\n",
    "num_mz_bins = dataset.shape[1]\n",
    "\n",
    "dataset_final = np.zeros((total_num_pixels, num_mz_bins))\n",
    "for mz_index in range(num_mz_bins):\n",
    "    ion_image_flat = dataset[:, mz_index]\n",
    "    ion_image = make_ion_image(ion_image_flat, image_shape, background_mask, fill_zeros=True, show_image=False)\n",
    "    dataset_final[:, mz_index] = ion_image.flatten()\n",
    "\n",
    "# Save to text file for DeepION\n",
    "np.savetxt(r'C:\\Users\\Leo\\Documents\\Second_paper\\Final_2nd_paper\\Final_final\\Comparisons\\Colocalization\\DeepION\\Data\\zebra_fish_for_DeepION_matrix.txt', dataset_final)\n",
    "del dataset, dataset_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d97e6676-f508-4d9d-a230-6271288edebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mass-to-charge ratios of the molecular species in each cluster\n",
    "mz_per_cluster = {}\n",
    "mz_per_cluster[1] = clustering_data_metadata['cluster_1']['mz'].tolist()\n",
    "mz_per_cluster[2] = clustering_data_metadata['cluster_2']['mz'].tolist()\n",
    "mz_per_cluster[3] = clustering_data_metadata['cluster_3']['mz'].tolist()\n",
    "mz_per_cluster[4] = clustering_data_metadata['cluster_4']['mz'].tolist()\n",
    "mz_per_cluster[5] = clustering_data_metadata['cluster_5']['mz'].tolist()\n",
    "mz_per_cluster[6] = clustering_data_metadata['cluster_6']['mz'].tolist()\n",
    "mz_per_cluster[7] = clustering_data_metadata['cluster_7']['mz'].tolist()\n",
    "mz_per_cluster[8] = clustering_data_metadata['cluster_8']['mz'].tolist()\n",
    "\n",
    "mz_list = []\n",
    "for cluster_label in range(1, 8): \n",
    "    mz_list.append(mz_per_cluster[cluster_label])\n",
    "\n",
    "mz_list = np.array(list(chain(*mz_list)))\n",
    "\n",
    "# Save as a CSV file for DeepION\n",
    "np.savetxt(r'C:\\Users\\Leo\\Documents\\Second_paper\\Final_2nd_paper\\Final_final\\Comparisons\\Colocalization\\DeepION\\Data\\zebra_fish_for_DeepION_peaks.csv', mz_list, delimiter=\",\", fmt=\"%d\", comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79330544-3863-4b53-95e7-c30af81a8f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a0b1a-5068-4c60-9864-a207465460c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24e25e40-44d7-4cfa-8fc1-e80eb49920f2",
   "metadata": {},
   "source": [
    "#### DeepION clustering workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dd83037-8d2c-4345-adbb-a2891484b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrix = r'C:\\Users\\Leo\\Documents\\Second_paper\\Final_2nd_paper\\Final_final\\Comparisons\\Colocalization\\DeepION\\Data\\zebra_fish_for_DeepION_matrix.txt'\n",
    "input_peak_list = r'C:\\Users\\Leo\\Documents\\Second_paper\\Final_2nd_paper\\Final_final\\Comparisons\\Colocalization\\DeepION\\Data\\zebra_fish_for_DeepION_peaks.csv'\n",
    "input_shape = image_shape # (height, width)\n",
    "mode = \"COL\"  # \"COL\" for colocalization\n",
    "ion_mode = \"positive\"\n",
    "num_co_localized = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449425a-de0f-4558-b854-2a36ae468019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b628b36-8f51-452a-a700-9c37df8ee81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f5ef603-ed8f-49e9-8cab-338fb6490487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DeepION training...\n",
      "Step 1: Start DeepION training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\anaconda3\\envs\\spatial_IMS_env_compare\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Leo\\anaconda3\\envs\\spatial_IMS_env_compare\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : batch : 0 loss: 4.1373\n",
      "epoch 1 : batch : 0 loss: 2.0272\n",
      "epoch 2 : batch : 0 loss: 1.7821\n",
      "epoch 3 : batch : 0 loss: 1.6976\n",
      "epoch 4 : batch : 0 loss: 1.6557\n",
      "epoch 5 : batch : 0 loss: 1.6060\n",
      "epoch 6 : batch : 0 loss: 1.6186\n",
      "epoch 7 : batch : 0 loss: 1.6166\n",
      "epoch 8 : batch : 0 loss: 1.5522\n",
      "epoch 9 : batch : 0 loss: 1.6005\n",
      "epoch 10 : batch : 0 loss: 1.5259\n",
      "epoch 11 : batch : 0 loss: 1.5008\n",
      "epoch 12 : batch : 0 loss: 1.4852\n",
      "epoch 13 : batch : 0 loss: 1.4512\n",
      "epoch 14 : batch : 0 loss: 1.4085\n",
      "epoch 15 : batch : 0 loss: 1.4504\n",
      "epoch 16 : batch : 0 loss: 1.3140\n",
      "epoch 17 : batch : 0 loss: 1.2945\n",
      "epoch 18 : batch : 0 loss: 1.2714\n",
      "epoch 19 : batch : 0 loss: 1.2325\n",
      "epoch 20 : batch : 0 loss: 1.1882\n",
      "epoch 21 : batch : 0 loss: 1.2191\n",
      "epoch 22 : batch : 0 loss: 1.1349\n",
      "epoch 23 : batch : 0 loss: 1.1509\n",
      "epoch 24 : batch : 0 loss: 1.0636\n",
      "epoch 25 : batch : 0 loss: 1.0175\n",
      "epoch 26 : batch : 0 loss: 0.9804\n",
      "epoch 27 : batch : 0 loss: 0.8786\n",
      "epoch 28 : batch : 0 loss: 0.8644\n",
      "epoch 29 : batch : 0 loss: 0.8455\n",
      "epoch 30 : batch : 0 loss: 0.9155\n",
      "epoch 31 : batch : 0 loss: 0.7390\n",
      "epoch 32 : batch : 0 loss: 0.7268\n",
      "epoch 33 : batch : 0 loss: 0.7557\n",
      "epoch 34 : batch : 0 loss: 0.6251\n",
      "epoch 35 : batch : 0 loss: 0.6319\n",
      "epoch 36 : batch : 0 loss: 0.5890\n",
      "epoch 37 : batch : 0 loss: 0.5672\n",
      "epoch 38 : batch : 0 loss: 0.5719\n",
      "epoch 39 : batch : 0 loss: 0.4974\n",
      "epoch 40 : batch : 0 loss: 0.5322\n",
      "epoch 41 : batch : 0 loss: 0.5193\n",
      "epoch 42 : batch : 0 loss: 0.4860\n",
      "epoch 43 : batch : 0 loss: 0.4042\n",
      "epoch 44 : batch : 0 loss: 0.3828\n",
      "epoch 45 : batch : 0 loss: 0.3665\n",
      "epoch 46 : batch : 0 loss: 0.3623\n",
      "epoch 47 : batch : 0 loss: 0.3202\n",
      "epoch 48 : batch : 0 loss: 0.3838\n",
      "epoch 49 : batch : 0 loss: 0.3161\n",
      "epoch 50 : batch : 0 loss: 0.2854\n",
      "epoch 51 : batch : 0 loss: 0.2782\n",
      "epoch 52 : batch : 0 loss: 0.3088\n",
      "epoch 53 : batch : 0 loss: 0.2730\n",
      "epoch 54 : batch : 0 loss: 0.2570\n",
      "epoch 55 : batch : 0 loss: 0.2822\n",
      "epoch 56 : batch : 0 loss: 0.2003\n",
      "epoch 57 : batch : 0 loss: 0.1974\n",
      "epoch 58 : batch : 0 loss: 0.2233\n",
      "epoch 59 : batch : 0 loss: 0.1979\n",
      "epoch 60 : batch : 0 loss: 0.1723\n",
      "epoch 61 : batch : 0 loss: 0.1611\n",
      "epoch 62 : batch : 0 loss: 0.1879\n",
      "epoch 63 : batch : 0 loss: 0.1543\n",
      "epoch 64 : batch : 0 loss: 0.1650\n",
      "epoch 65 : batch : 0 loss: 0.1493\n",
      "epoch 66 : batch : 0 loss: 0.1543\n",
      "epoch 67 : batch : 0 loss: 0.1441\n",
      "epoch 68 : batch : 0 loss: 0.1364\n",
      "epoch 69 : batch : 0 loss: 0.1139\n",
      "epoch 70 : batch : 0 loss: 0.1286\n",
      "epoch 71 : batch : 0 loss: 0.1568\n",
      "epoch 72 : batch : 0 loss: 0.1067\n",
      "epoch 73 : batch : 0 loss: 0.1385\n",
      "epoch 74 : batch : 0 loss: 0.0882\n",
      "epoch 75 : batch : 0 loss: 0.1044\n",
      "epoch 76 : batch : 0 loss: 0.1320\n",
      "epoch 77 : batch : 0 loss: 0.1062\n",
      "epoch 78 : batch : 0 loss: 0.0847\n",
      "epoch 79 : batch : 0 loss: 0.0949\n",
      "epoch 80 : batch : 0 loss: 0.0897\n",
      "epoch 81 : batch : 0 loss: 0.1114\n",
      "epoch 82 : batch : 0 loss: 0.0806\n",
      "epoch 83 : batch : 0 loss: 0.0989\n",
      "epoch 84 : batch : 0 loss: 0.0825\n",
      "epoch 85 : batch : 0 loss: 0.0779\n",
      "epoch 86 : batch : 0 loss: 0.0937\n",
      "epoch 87 : batch : 0 loss: 0.0869\n",
      "epoch 88 : batch : 0 loss: 0.0744\n",
      "epoch 89 : batch : 0 loss: 0.0762\n",
      "epoch 90 : batch : 0 loss: 0.0800\n",
      "epoch 91 : batch : 0 loss: 0.0734\n",
      "epoch 92 : batch : 0 loss: 0.0710\n",
      "epoch 93 : batch : 0 loss: 0.0525\n",
      "epoch 94 : batch : 0 loss: 0.0648\n",
      "epoch 95 : batch : 0 loss: 0.0809\n",
      "epoch 96 : batch : 0 loss: 0.0942\n",
      "epoch 97 : batch : 0 loss: 0.0645\n",
      "epoch 98 : batch : 0 loss: 0.0649\n",
      "epoch 99 : batch : 0 loss: 0.0823\n",
      "epoch 100 : batch : 0 loss: 0.0628\n",
      "epoch 101 : batch : 0 loss: 0.0535\n",
      "epoch 102 : batch : 0 loss: 0.0547\n",
      "epoch 103 : batch : 0 loss: 0.0510\n",
      "epoch 104 : batch : 0 loss: 0.0479\n",
      "epoch 105 : batch : 0 loss: 0.0614\n",
      "epoch 106 : batch : 0 loss: 0.0532\n",
      "epoch 107 : batch : 0 loss: 0.0855\n",
      "epoch 108 : batch : 0 loss: 0.0634\n",
      "epoch 109 : batch : 0 loss: 0.0631\n",
      "epoch 110 : batch : 0 loss: 0.0602\n",
      "epoch 111 : batch : 0 loss: 0.0600\n",
      "epoch 112 : batch : 0 loss: 0.0626\n",
      "epoch 113 : batch : 0 loss: 0.0490\n",
      "epoch 114 : batch : 0 loss: 0.0456\n",
      "epoch 115 : batch : 0 loss: 0.0629\n",
      "epoch 116 : batch : 0 loss: 0.0409\n",
      "epoch 117 : batch : 0 loss: 0.0622\n",
      "epoch 118 : batch : 0 loss: 0.0426\n",
      "epoch 119 : batch : 0 loss: 0.0562\n",
      "epoch 120 : batch : 0 loss: 0.0429\n",
      "epoch 121 : batch : 0 loss: 0.0369\n",
      "epoch 122 : batch : 0 loss: 0.0389\n",
      "epoch 123 : batch : 0 loss: 0.0452\n",
      "epoch 124 : batch : 0 loss: 0.0336\n",
      "epoch 125 : batch : 0 loss: 0.0402\n",
      "epoch 126 : batch : 0 loss: 0.0559\n",
      "epoch 127 : batch : 0 loss: 0.0445\n",
      "epoch 128 : batch : 0 loss: 0.0512\n",
      "epoch 129 : batch : 0 loss: 0.0379\n",
      "epoch 130 : batch : 0 loss: 0.0406\n",
      "epoch 131 : batch : 0 loss: 0.0422\n",
      "epoch 132 : batch : 0 loss: 0.0356\n",
      "epoch 133 : batch : 0 loss: 0.0560\n",
      "epoch 134 : batch : 0 loss: 0.0451\n",
      "epoch 135 : batch : 0 loss: 0.0473\n",
      "epoch 136 : batch : 0 loss: 0.0691\n",
      "epoch 137 : batch : 0 loss: 0.0630\n",
      "epoch 138 : batch : 0 loss: 0.0589\n",
      "epoch 139 : batch : 0 loss: 0.0540\n",
      "epoch 140 : batch : 0 loss: 0.0511\n",
      "epoch 141 : batch : 0 loss: 0.1225\n",
      "epoch 142 : batch : 0 loss: 0.0447\n",
      "epoch 143 : batch : 0 loss: 0.0302\n",
      "epoch 144 : batch : 0 loss: 0.0402\n",
      "epoch 145 : batch : 0 loss: 0.0381\n",
      "epoch 146 : batch : 0 loss: 0.0370\n",
      "epoch 147 : batch : 0 loss: 0.0242\n",
      "epoch 148 : batch : 0 loss: 0.1632\n",
      "epoch 149 : batch : 0 loss: 0.0805\n",
      "epoch 150 : batch : 0 loss: 0.0448\n",
      "epoch 151 : batch : 0 loss: 0.0382\n",
      "epoch 152 : batch : 0 loss: 0.0276\n",
      "epoch 153 : batch : 0 loss: 0.0473\n",
      "epoch 154 : batch : 0 loss: 0.0354\n",
      "epoch 155 : batch : 0 loss: 0.0382\n",
      "epoch 156 : batch : 0 loss: 0.0497\n",
      "epoch 157 : batch : 0 loss: 0.0340\n",
      "epoch 158 : batch : 0 loss: 0.0344\n",
      "epoch 159 : batch : 0 loss: 0.0563\n",
      "epoch 160 : batch : 0 loss: 0.0316\n",
      "epoch 161 : batch : 0 loss: 0.0274\n",
      "epoch 162 : batch : 0 loss: 0.0297\n",
      "epoch 163 : batch : 0 loss: 0.0273\n",
      "epoch 164 : batch : 0 loss: 0.0340\n",
      "epoch 165 : batch : 0 loss: 0.0289\n",
      "epoch 166 : batch : 0 loss: 0.0315\n",
      "epoch 167 : batch : 0 loss: 0.0284\n",
      "epoch 168 : batch : 0 loss: 0.0307\n",
      "epoch 169 : batch : 0 loss: 0.0269\n",
      "epoch 170 : batch : 0 loss: 0.0326\n",
      "epoch 171 : batch : 0 loss: 0.0243\n",
      "epoch 172 : batch : 0 loss: 0.0284\n",
      "epoch 173 : batch : 0 loss: 0.0300\n",
      "epoch 174 : batch : 0 loss: 0.0196\n",
      "epoch 175 : batch : 0 loss: 0.0221\n",
      "epoch 176 : batch : 0 loss: 0.0253\n",
      "epoch 177 : batch : 0 loss: 0.0212\n",
      "epoch 178 : batch : 0 loss: 0.0277\n",
      "epoch 179 : batch : 0 loss: 0.0257\n",
      "epoch 180 : batch : 0 loss: 0.0259\n",
      "epoch 181 : batch : 0 loss: 0.0212\n",
      "epoch 182 : batch : 0 loss: 0.0263\n",
      "epoch 183 : batch : 0 loss: 0.0273\n",
      "epoch 184 : batch : 0 loss: 0.0223\n",
      "epoch 185 : batch : 0 loss: 0.0400\n",
      "epoch 186 : batch : 0 loss: 0.0275\n",
      "epoch 187 : batch : 0 loss: 0.0245\n",
      "epoch 188 : batch : 0 loss: 0.0364\n",
      "epoch 189 : batch : 0 loss: 0.0267\n",
      "epoch 190 : batch : 0 loss: 0.0210\n",
      "epoch 191 : batch : 0 loss: 0.0273\n",
      "epoch 192 : batch : 0 loss: 0.0255\n",
      "epoch 193 : batch : 0 loss: 0.0281\n",
      "epoch 194 : batch : 0 loss: 0.0259\n",
      "epoch 195 : batch : 0 loss: 0.0205\n",
      "epoch 196 : batch : 0 loss: 0.0274\n",
      "epoch 197 : batch : 0 loss: 0.0303\n",
      "epoch 198 : batch : 0 loss: 0.0311\n",
      "epoch 199 : batch : 0 loss: 0.1469\n",
      "Training completed!\n",
      "Extracting features using DeepION...\n",
      "Step 2: Start DeepION predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\anaconda3\\envs\\spatial_IMS_env_compare\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Leo\\anaconda3\\envs\\spatial_IMS_env_compare\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "train_deepion(input_matrix, input_shape, mode)\n",
    "features = predict_deepion(input_matrix, input_shape, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2057ff7-b7c8-41c4-aa4b-045b1ababe9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0056a1ec-0829-4b17-9e48-fdb1f151a3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying dimensionality reduction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\anaconda3\\envs\\spatial_IMS_env_compare\\Lib\\site-packages\\umap\\umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality reduction completed!\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality reduction with UMAP\n",
    "features_umap = reduce_dimensionality(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c8ec5-cc0f-4f27-940a-bd886f365492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28515793-a301-4650-9988-0d4a2999e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDBSCAN clustering\n",
    "HDBSCAN_model = HDBSCAN(min_cluster_size=5, max_cluster_size=50, metric=\"euclidean\", n_jobs=-1)\n",
    "HDBSCAN_model.fit(features_umap)\n",
    "DeepION_labels = HDBSCAN_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1917d00-7dc5-4d4e-8bf6-bde0b32edcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepION execution time: 4651.384867 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "compute_time = end_time - start_time\n",
    "print(f\"DeepION execution time: {compute_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b4ada2-20fd-45f9-976e-25e2656ce28b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e32086-c102-45f0-86b0-0ddc19a927ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ba65b7f-b02f-49ff-acc5-841d9eda2444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand index: 0.5589\n",
      "Adjusted mutual information: 0.7472\n",
      "Balanced adjusted Rand index: 0.7598\n",
      "Balanced V-measure: 0.8661\n"
     ]
    }
   ],
   "source": [
    "# Clustering performance \n",
    "ARI = np.round(adjusted_rand_score(ref_labels, DeepION_labels), 4)\n",
    "print('Adjusted Rand index:', ARI)\n",
    "AMI = np.round(adjusted_mutual_info_score(ref_labels, DeepION_labels, average_method='arithmetic'), 4)\n",
    "print('Adjusted mutual information:', AMI)\n",
    "BARI = np.round(balanced_adjusted_rand_index(np.array(ref_labels), np.array(DeepION_labels)), 4)\n",
    "print('Balanced adjusted Rand index:', BARI)\n",
    "balanced_homogeneity, balanced_completeness, balanced_v_measure = np.round(balanced_homogeneity_completeness_v_measure(np.array(ref_labels), np.array(DeepION_labels)), 4)\n",
    "print('Balanced V-measure:', balanced_v_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d37235-625a-4c56-9234-0c58d4466540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa98265-63c0-4768-8a35-1603de598a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
