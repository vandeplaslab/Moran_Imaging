{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb0beffd-d06c-48b8-bf4c-cecadbdb73d2",
   "metadata": {},
   "source": [
    "### Colocalization-based ion image clusternig with DeepION\n",
    "\n",
    "Publication: \"DeepION: A Deep Learning-Based Low-Dimensional Representation Model of Ion Images for Mass Spectrometry Imaging\" by Lei Guo. Analytical Chemistry. 2024. https://pubs.acs.org/doi/full/10.1021/acs.analchem.3c05002\n",
    "\n",
    "Code by Lei Guo: https://github.com/gankLei-X/DeepION/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db7ec2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38445b1-f1d4-4395-870d-37fd416f78eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lgmigas/Documents/GitHub/Moran_Imaging/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import HDBSCAN\n",
    "import random\n",
    "import umap\n",
    "from pathlib import Path\n",
    "\n",
    "# Import necessary Moran Imaging modules\n",
    "from moran_imaging.ari_balance import balanced_adjusted_rand_index\n",
    "from moran_imaging.vmeasure_balance import balanced_homogeneity_completeness_v_measure\n",
    "\n",
    "# Import necessary DeepION module\n",
    "from moran_imaging.deep_ion_clustering import DeepION_training, DeepION_predicting\n",
    "\n",
    "# Fix random seed\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008d2b73-f73e-4d27-b7b6-8916e3f1eed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n",
      "No GPU found, using CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# Verify GPU availability\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))  \n",
    "    print(\"Torch CUDA Version:\", torch.version.cuda)\n",
    "    print(\"Torch Backend CUDA Available:\", torch.backends.cudnn.enabled)\n",
    "\n",
    "    # Set CUDA device \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "else:\n",
    "    print(\"No GPU found, using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e1b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    backend = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    backend = \"mps\"\n",
    "else:\n",
    "    backend = \"cpu\"\n",
    "torch.set_default_device(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f08ddee1-0997-4cbd-8fbe-4e2a16d13b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ion_image(data, image_shape, background_mask, fill_zeros=True, show_image=True, colormap='coolwarm'):\n",
    "    \n",
    "    # Fill background pixels with zeros (default) or NaN\n",
    "    pixel_grid = np.zeros((image_shape[0]*image_shape[1], ))\n",
    "    pixel_grid[np.invert(background_mask)] = data\n",
    "    \n",
    "    if not fill_zeros:\n",
    "        pixel_grid[background_mask] = np.nan\n",
    "    \n",
    "    # Reshape data\n",
    "    ion_image = np.reshape(pixel_grid, image_shape)\n",
    "    \n",
    "    # Plot ion image \n",
    "    if show_image: \n",
    "        plt.figure(dpi=100)\n",
    "        plt.imshow(ion_image, cmap=colormap)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return ion_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a688eedf-b816-445a-8ade-1b9c039e3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train DeepION model\n",
    "def train_deepion(input_matrix, input_shape, mode=\"COL\"):\n",
    "    \"\"\"\n",
    "    Runs DeepION training with the given MSI dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        input_matrix (str): Path to the MSI data matrix file.\n",
    "        input_shape (tuple): Shape of the MSI dataset (height, width).\n",
    "        mode (str): Mode of operation, either 'COL' (colocalization) or 'ISO' (isotope discovery).\n",
    "    \"\"\"\n",
    "    print(\"Starting DeepION training...\")\n",
    "    DeepION_training(input_matrix, input_shape, mode)\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "# Function to run DeepION feature extraction\n",
    "def predict_deepion(input_matrix, input_shape, mode=\"COL\"):\n",
    "    \"\"\"\n",
    "    Runs DeepION feature extraction on the given MSI dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        input_matrix (str): Path to the MSI data matrix file.\n",
    "        input_shape (tuple): Shape of the MSI dataset (height, width).\n",
    "        mode (str): Mode of operation, either 'COL' (colocalization) or 'ISO' (isotope discovery).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Extracted feature matrix.\n",
    "    \"\"\"\n",
    "    print(\"Extracting features using DeepION...\")\n",
    "    features = DeepION_predicting(input_matrix, input_shape, mode)\n",
    "    print(\"Feature extraction completed!\")\n",
    "    return features\n",
    "\n",
    "# Function to apply dimensionality reduction\n",
    "def reduce_dimensionality(features):\n",
    "    \"\"\"\n",
    "    Applies dimensionality reduction to extracted features.\n",
    "    \n",
    "    Parameters:\n",
    "        features (np.ndarray): Feature matrix extracted from DeepION.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Low-dimensional feature representation.\n",
    "    \"\"\"\n",
    "    print(\"Applying dimensionality reduction...\")\n",
    "\n",
    "    features_umap = umap.UMAP(n_components=20, metric='cosine', random_state=0).fit_transform(features)\n",
    "    features_umap = MinMaxScaler().fit_transform(features_umap)\n",
    "    \n",
    "    print(\"Dimensionality reduction completed!\")\n",
    "    return features_umap\n",
    "\n",
    "# # Function to run co-localized ion searching\n",
    "# def run_colocalized_search(ld_features, peak_list, num=5, output_file=\"output/\"):\n",
    "#     \"\"\"\n",
    "#     Runs co-localized ion searching using DeepION features.\n",
    "    \n",
    "#     Parameters:\n",
    "#         ld_features (np.ndarray): Low-dimensional feature representation.\n",
    "#         peak_list (str): Path to MSI peak list file.\n",
    "#         num (int): Number of co-localized ions to search for each ion.\n",
    "#         output_file (str): Path to save results.\n",
    "#     \"\"\"\n",
    "#     print(f\"Running co-localized ion searching (Top {num} ions)...\")\n",
    "#     Co_localizedIONSearching(ld_features, peak_list, num, output_file)\n",
    "#     print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9fe2bc-c1d3-4e13-886a-b6aef03e8307",
   "metadata": {},
   "source": [
    "#### Transform zebra-fish dataset into a DeepION-compatible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2ab545f-7716-4c02-aea2-883b8ed23695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_dir = Path(\".\").resolve() / \"Data\"\n",
    "assert data_dir.exists(), f\"The data directory {data_dir} does not exist.\"\n",
    "\n",
    "pickle_file = data_dir / \"Zebra_fish_8_clusters_dataset.pickle\"\n",
    "assert pickle_file.exists(), f\"The pickle file {pickle_file} does not exist.\"\n",
    "\n",
    "with open(pickle_file, 'rb') as file:\n",
    "    clustering_data_metadata = pickle.load(file) \n",
    "\n",
    "# create results directory\n",
    "results_dir = data_dir.parent / \"Results\" / \"DeepION_Clustering\"\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "image_shape = clustering_data_metadata['utils']['image_shape']\n",
    "background_mask = clustering_data_metadata['utils']['background_mask']\n",
    "data_cluster1 = clustering_data_metadata['cluster_1']['data'] \n",
    "data_cluster2 = clustering_data_metadata['cluster_2']['data']\n",
    "data_cluster3 = clustering_data_metadata['cluster_3']['data']\n",
    "data_cluster4 = clustering_data_metadata['cluster_4']['data']\n",
    "data_cluster5 = clustering_data_metadata['cluster_5']['data']\n",
    "data_cluster6 = clustering_data_metadata['cluster_6']['data']\n",
    "data_cluster7 = clustering_data_metadata['cluster_7']['data']\n",
    "data_cluster8 = clustering_data_metadata['cluster_8']['data']\n",
    "\n",
    "# Reference cluster labels\n",
    "ref_labels = ([1]*data_cluster1.shape[1] + [2]*data_cluster2.shape[1] + [3]*data_cluster3.shape[1] + [4]*data_cluster4.shape[1] + [5]*data_cluster5.shape[1] +\n",
    "              [6]*data_cluster6.shape[1] + [7]*data_cluster7.shape[1] + [8]*data_cluster8.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6439e3c0-b428-4b6d-a64b-a9af3267e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add off-tissue pixels to each ion image\n",
    "deepion_matrix_file = results_dir / \"zebra_fish_for_DeepION_matrix.txt\"\n",
    "if not deepion_matrix_file.exists():\n",
    "    dataset = np.hstack((data_cluster1, data_cluster2, data_cluster3, data_cluster4, data_cluster5, data_cluster6, data_cluster7, data_cluster8))\n",
    "    total_num_pixels = np.prod(image_shape)\n",
    "    num_mz_bins = dataset.shape[1]\n",
    "\n",
    "    dataset_final = np.zeros((total_num_pixels, num_mz_bins))\n",
    "    for mz_index in range(num_mz_bins):\n",
    "        ion_image_flat = dataset[:, mz_index]\n",
    "        ion_image = make_ion_image(ion_image_flat, image_shape, background_mask, fill_zeros=True, show_image=False)\n",
    "        dataset_final[:, mz_index] = ion_image.flatten()\n",
    "    # Save to text file for DeepION\n",
    "    np.savetxt(deepion_matrix_file, dataset_final)\n",
    "    del dataset, dataset_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97e6676-f508-4d9d-a230-6271288edebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepion_peaks_file = results_dir / \"zebra_fish_for_DeepION_peaks.txt\"\n",
    "if not deepion_peaks_file.exists():\n",
    "    # Mass-to-charge ratios of the molecular species in each cluster\n",
    "    mz_per_cluster = {}\n",
    "    mz_per_cluster[1] = clustering_data_metadata['cluster_1']['mz'].tolist()\n",
    "    mz_per_cluster[2] = clustering_data_metadata['cluster_2']['mz'].tolist()\n",
    "    mz_per_cluster[3] = clustering_data_metadata['cluster_3']['mz'].tolist()\n",
    "    mz_per_cluster[4] = clustering_data_metadata['cluster_4']['mz'].tolist()\n",
    "    mz_per_cluster[5] = clustering_data_metadata['cluster_5']['mz'].tolist()\n",
    "    mz_per_cluster[6] = clustering_data_metadata['cluster_6']['mz'].tolist()\n",
    "    mz_per_cluster[7] = clustering_data_metadata['cluster_7']['mz'].tolist()\n",
    "    mz_per_cluster[8] = clustering_data_metadata['cluster_8']['mz'].tolist()\n",
    "\n",
    "    mz_list = []\n",
    "    for cluster_label in range(1, 8): \n",
    "        mz_list.append(mz_per_cluster[cluster_label])\n",
    "\n",
    "    mz_list = np.array(list(chain(*mz_list)))\n",
    "\n",
    "    # Save as a CSV file for DeepION\n",
    "    np.savetxt(deepion_peaks_file, mz_list, delimiter=\",\", fmt=\"%d\", comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e25e40-44d7-4cfa-8fc1-e80eb49920f2",
   "metadata": {},
   "source": [
    "#### DeepION clustering workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f5ef603-ed8f-49e9-8cab-338fb6490487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DeepION training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 256, 256]) False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:19<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m ion_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m num_co_localized \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrain_deepion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepion_matrix_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m features \u001b[38;5;241m=\u001b[39m predict_deepion(deepion_matrix_file, input_shape, mode)\n",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mtrain_deepion\u001b[0;34m(input_matrix, input_shape, mode)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mRuns DeepION training with the given MSI dataset.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    mode (str): Mode of operation, either 'COL' (colocalization) or 'ISO' (isotope discovery).\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting DeepION training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mDeepION_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Moran_Imaging/src/moran_imaging/deep_ion_clustering.py:175\u001b[0m, in \u001b[0;36mDeepION_training\u001b[0;34m(input_filename, image_size, mode, mini_batch, n_epoch)\u001b[0m\n\u001b[1;32m    173\u001b[0m loss \u001b[38;5;241m=\u001b[39m learner(images)\n\u001b[1;32m    174\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 175\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    177\u001b[0m learner\u001b[38;5;241m.\u001b[39mupdate_moving_average()\n",
      "File \u001b[0;32m~/Documents/GitHub/Moran_Imaging/venv/lib/python3.10/site-packages/torch/_tensor.py:616\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m        used to compute the :attr:`tensors`. Defaults to ``None``.\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    627\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/Moran_Imaging/venv/lib/python3.10/site-packages/torch/overrides.py:1728\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1725\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1726\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1727\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1728\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1729\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1730\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/GitHub/Moran_Imaging/venv/lib/python3.10/site-packages/torch/utils/_device.py:103\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Moran_Imaging/venv/lib/python3.10/site-packages/torch/_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    624\u001b[0m     )\n\u001b[0;32m--> 625\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Moran_Imaging/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Moran_Imaging/venv/lib/python3.10/site-packages/torch/autograd/graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "input_shape = image_shape # (height, width)\n",
    "mode = \"COL\"  # \"COL\" for colocalization\n",
    "ion_mode = \"positive\"\n",
    "num_co_localized = 10\n",
    "\n",
    "train_deepion(deepion_matrix_file, input_shape, mode)\n",
    "features = predict_deepion(deepion_matrix_file, input_shape, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056a1ec-0829-4b17-9e48-fdb1f151a3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying dimensionality reduction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\anaconda3\\envs\\spatial_IMS_env_compare\\Lib\\site-packages\\umap\\umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality reduction completed!\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality reduction with UMAP\n",
    "features_umap = reduce_dimensionality(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c8ec5-cc0f-4f27-940a-bd886f365492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28515793-a301-4650-9988-0d4a2999e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDBSCAN clustering\n",
    "HDBSCAN_model = HDBSCAN(min_cluster_size=5, max_cluster_size=50, metric=\"euclidean\", n_jobs=-1)\n",
    "HDBSCAN_model.fit(features_umap)\n",
    "DeepION_labels = HDBSCAN_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1917d00-7dc5-4d4e-8bf6-bde0b32edcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepION execution time: 4651.384867 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "compute_time = end_time - start_time\n",
    "print(f\"DeepION execution time: {compute_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b4ada2-20fd-45f9-976e-25e2656ce28b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e32086-c102-45f0-86b0-0ddc19a927ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba65b7f-b02f-49ff-acc5-841d9eda2444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand index: 0.5589\n",
      "Adjusted mutual information: 0.7472\n",
      "Balanced adjusted Rand index: 0.7598\n",
      "Balanced V-measure: 0.8661\n"
     ]
    }
   ],
   "source": [
    "# Clustering performance \n",
    "ARI = np.round(adjusted_rand_score(ref_labels, DeepION_labels), 4)\n",
    "print('Adjusted Rand index:', ARI)\n",
    "AMI = np.round(adjusted_mutual_info_score(ref_labels, DeepION_labels, average_method='arithmetic'), 4)\n",
    "print('Adjusted mutual information:', AMI)\n",
    "BARI = np.round(balanced_adjusted_rand_index(np.array(ref_labels), np.array(DeepION_labels)), 4)\n",
    "print('Balanced adjusted Rand index:', BARI)\n",
    "balanced_homogeneity, balanced_completeness, balanced_v_measure = np.round(balanced_homogeneity_completeness_v_measure(np.array(ref_labels), np.array(DeepION_labels)), 4)\n",
    "print('Balanced V-measure:', balanced_v_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d37235-625a-4c56-9234-0c58d4466540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa98265-63c0-4768-8a35-1603de598a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
