{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colocalization-based ion image clusternig with NRDC\n",
    "\n",
    "Publication: \"A noise-robust deep clustering of biomolecular ions improves interpretability of mass spectrometric images\" by Dan Guo. Bioinformatics. 2023. https://academic.oup.com/bioinformatics/article/39/2/btad067/7028486\n",
    "\n",
    "Code by Tim Daniel Rose: https://github.com/tdrose/deep_mzClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import h5py\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "# Fix random seed\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Moran Imaging modules\n",
    "from moran_imaging.ari_balance import balanced_adjusted_rand_index\n",
    "import moran_imaging.nrdc_clustering as NRDC\n",
    "from moran_imaging.plotting import position_discrete_colorbar_ticks\n",
    "from moran_imaging.vmeasure_balance import balanced_homogeneity_completeness_v_measure\n",
    "\n",
    "# Import necessary NRDC module\n",
    "import moran_imaging.nrdc_clustering as NRDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load imaging mass spectrometry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "with open('Zebra_fish_8_clusters_dataset.pickle', 'rb') as file:\n",
    "    clustering_data_metadata = pickle.load(file) \n",
    "\n",
    "image_shape = clustering_data_metadata['utils']['image_shape']\n",
    "background_mask = clustering_data_metadata['utils']['background_mask']\n",
    "data_cluster1 = clustering_data_metadata['cluster_1']['data'] \n",
    "data_cluster2 = clustering_data_metadata['cluster_2']['data']\n",
    "data_cluster3 = clustering_data_metadata['cluster_3']['data']\n",
    "data_cluster4 = clustering_data_metadata['cluster_4']['data']\n",
    "data_cluster5 = clustering_data_metadata['cluster_5']['data']\n",
    "data_cluster6 = clustering_data_metadata['cluster_6']['data']\n",
    "data_cluster7 = clustering_data_metadata['cluster_7']['data']\n",
    "data_cluster8 = clustering_data_metadata['cluster_8']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.hstack((data_cluster1, data_cluster2, data_cluster3, data_cluster4, data_cluster5, data_cluster6, data_cluster7, data_cluster8))\n",
    "\n",
    "ref_labels = ([1]*data_cluster1.shape[1] + [2]*data_cluster2.shape[1] + [3]*data_cluster3.shape[1] + [4]*data_cluster4.shape[1] + [5]*data_cluster5.shape[1] +\n",
    "              [6]*data_cluster6.shape[1] + [7]*data_cluster7.shape[1] + [8]*data_cluster8.shape[1])\n",
    "\n",
    "total_num_pixels = np.prod(image_shape)\n",
    "num_mz_bins = dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise-robust deep clustering (NRDC) workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch: 0 Loss: 0.244656\n",
      "Pretraining Epoch: 1 Loss: 0.175149\n",
      "Pretraining Epoch: 2 Loss: 0.064030\n",
      "Pretraining Epoch: 3 Loss: 0.039744\n",
      "Pretraining Epoch: 4 Loss: 0.035048\n",
      "Pretraining Epoch: 5 Loss: 0.024816\n",
      "Pretraining Epoch: 6 Loss: 0.021108\n",
      "Pretraining Epoch: 7 Loss: 0.020902\n",
      "Pretraining Epoch: 8 Loss: 0.020860\n",
      "Pretraining Epoch: 9 Loss: 0.020213\n",
      "Pretraining Epoch: 10 Loss: 0.016337\n",
      "Training Epoch: 0 Loss: 0.020664\n",
      "Training Epoch: 1 Loss: 0.007033\n",
      "Training Epoch: 2 Loss: 0.004580\n",
      "Training Epoch: 3 Loss: 0.003510\n",
      "Training Epoch: 4 Loss: 0.003108\n",
      "Training Epoch: 5 Loss: 0.002783\n",
      "Training Epoch: 6 Loss: 0.002453\n",
      "Training Epoch: 7 Loss: 0.002349\n",
      "Training Epoch: 8 Loss: 0.001895\n",
      "Training Epoch: 9 Loss: 0.001738\n",
      "Training Epoch: 10 Loss: 0.001549\n",
      "Noise robust deep clustering execution time: 32612.882143 seconds\n"
     ]
    }
   ],
   "source": [
    "# If you have access to a GPU, set use_gpu to True\n",
    "start_time = time.time()\n",
    "\n",
    "NRDC_cluster_model = NRDC.Deep_Clustering(dataset, np.invert(background_mask), image_shape, num_cluster=8, lr=0.0001, knn=True, k=5, use_gpu=True, random_seed=0)\n",
    "cae, CLUST = NRDC_cluster_model.train()\n",
    "NRDC_labels = NRDC_cluster_model.inference(cae, CLUST)\n",
    "\n",
    "end_time = time.time()\n",
    "compute_time = end_time - start_time\n",
    "print(f\"Noise robust deep clustering execution time: {compute_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand index: 0.6217\n",
      "Adjusted mutual information: 0.7191\n",
      "Balanced adjusted Rand index: 0.4849\n",
      "Balanced V-measure: 0.7199\n"
     ]
    }
   ],
   "source": [
    "# Deep clustering performance \n",
    "ARI = np.round(adjusted_rand_score(ref_labels, NRDC_labels), 4)\n",
    "print('Adjusted Rand index:', ARI)\n",
    "AMI = np.round(adjusted_mutual_info_score(ref_labels, NRDC_labels, average_method='arithmetic'), 4)\n",
    "print('Adjusted mutual information:', AMI)\n",
    "BARI = np.round(balanced_adjusted_rand_index(np.array(ref_labels), np.array(NRDC_labels)), 4)\n",
    "print('Balanced adjusted Rand index:', BARI)\n",
    "balanced_homogeneity, balanced_completeness, balanced_v_measure = np.round(balanced_homogeneity_completeness_v_measure(np.array(ref_labels), np.array(NRDC_labels)), 4)\n",
    "print('Balanced V-measure:', balanced_v_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
